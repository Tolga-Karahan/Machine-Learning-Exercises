{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='files/bayes.png'/>\n",
    "<pre>                                                     Bayes Teoremi</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayes Teoremi elimizdeki öncül bilgilere göre olasılık hesabı yapmamızı sağlar.\n",
    "# B olayı gerçekleştikten sonra A olayının gerçekleşme olasılığının hesaplanması \n",
    "# yukarıdaki gibidir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayes Teoremi'nden faydalanarak bir Bayes Sınıflandırıcısı oluşturabiliriz. \n",
    "# Bayes Sınıflandırıcısı her bir faktör için olasılıkları hesaplar ve en yüksek olasılığı\n",
    "# veren faktörü seçer. Girdi özniteliklerinin birbirinden bağımsız olduğu varsayılır.\n",
    "# Gerçek zamanlı tahmin, metin sınıflandırma, spam filtreleme, öneri sistemleri gibi\n",
    "# pratik uygulamalarda kullanılmaktadır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Öncelikle maillerde bulunan kelimeleri ve bu kelimelerin frekanslarını içeren bir sözlük\n",
    "# oluşturacağız. Ardından bu sözlük üzerinde bazı kelimeleri sileceğiz. Bu kelimeler analize\n",
    "# bir katkısı olmayan sayısal değerler ve ya 'this', 'is', 'are' gibi kelimeler olacak. Bunu\n",
    "# sağlayabilmek için uzunluğu 5 harften az olan kelimeleri ve sayısal değerleri atacağız.\n",
    "# Son olarak sözlüğümüzdeki en sık 3bin kelimeyi seçerek sözlüğümüzü kısaltacağız.\n",
    "# Modelimiz adı üstünde naif. Kelimelerin gerçekte birbirinden bağımsız olduğunu varsayıyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pathleri tanımlayalım\n",
    "training_path = '../Datasets/Mails-Dataset/training-mails'\n",
    "test_path     = '../Datasets/Mails-Dataset/test-mails'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Sözlüğümüzü oluşturalım\n",
    "def create_dictionary(dir):\n",
    "    all_words = []\n",
    "    emails = [os.path.join(dir, file) for file in os.listdir(dir)]\n",
    "    \n",
    "    for mail in emails:\n",
    "        with open(mail) as m:\n",
    "            for line in m:\n",
    "                all_words += line.split()\n",
    "                \n",
    "    dictionary = Counter(all_words)\n",
    "    words = list(dictionary)\n",
    "    \n",
    "    for word in words:\n",
    "        if word.isalpha() == False:\n",
    "            del dictionary[word]\n",
    "        if len(word) < 5:\n",
    "            del dictionary[word]\n",
    "            \n",
    "    # Sözlükte bulunmayan kelimeleri temsil etmek için bir anahtar oluşturalım\n",
    "    dictionary = dictionary.most_common(3000)\n",
    "    \n",
    "    # Kelimeleri anahtar, değerleri ise indis-frekans ikilileri yaptık\n",
    "    # Böylece her bir kelime unique indise sahip oldu\n",
    "    dictionary = {dictionary[index][0]:(index, dictionary[index][1]) for index in range(len(dictionary))}\n",
    "    \n",
    "    return dictionary\n",
    "\n",
    "dictionary = create_dictionary(training_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Öznitelik matrisini oluşturalım. Öznitelik matrisinin her bir satırı her bir mail\n",
    "# için öznitelik vektörüne karşılık gelir. Bu vektör sözlük uzunluğu kadar bileşene\n",
    "# sahiptir. Bu bileşenlerin her biri bir kelimeye karşılık düşer ve mail içerisinde\n",
    "# ilgili kelimenin sıklığını verir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_feature_matrix(dir, dictionary):\n",
    "    \n",
    "    # Email pathlerini alalım\n",
    "    emails = [os.path.join(dir, file) for file in os.listdir(dir)]\n",
    "    \n",
    "    # Öznitelik matrisi ve etiket vektörünü başlatalım\n",
    "    feature_matrix = np.zeros((len(emails), len(dictionary)))\n",
    "    labels = np.zeros(len(emails))\n",
    "    \n",
    "    for doc_id, mail in enumerate(emails):\n",
    "        with open(mail) as m:\n",
    "            # İçerik 2. satırda bulunuyor\n",
    "            content = m.readlines()[2]\n",
    "            \n",
    "            words = content.split()\n",
    "            for word in words:\n",
    "                if word in dictionary:\n",
    "                    word_index = dictionary[word][0]\n",
    "                    freq = words.count(word)\n",
    "                    feature_matrix[doc_id][word_index] = freq\n",
    "                \n",
    "        # Etiketi belirleyelim\n",
    "        suffix = mail.split('/')[-1]\n",
    "        if suffix.startswith('spmsg'):\n",
    "            labels[doc_id] = 1\n",
    "        else:\n",
    "            labels[doc_id] = 0\n",
    "    \n",
    "    return feature_matrix, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelimizi Gauss dağılımını kullanarak kuralım\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "training_features_matrix, training_labels = create_feature_matrix(training_path, dictionary)\n",
    "test_features_matrix, test_labels = create_feature_matrix(test_path, dictionary)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(training_features_matrix, training_labels)\n",
    "\n",
    "# Tahminlerimizi yapalım\n",
    "predictions = model.predict(test_features_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model:  0.9730769230769231\n"
     ]
    }
   ],
   "source": [
    "# Modelimizin isabet oranına bakalım\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(predictions, test_labels)\n",
    "print('Accuracy of model: ', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
